{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c1:[12 15 16 14 21 23 25]\n",
      "c2:[2 4 6 3]\n",
      "c3:[31 38 35 30]\n",
      "Cluster centers are: \n",
      "[[18.  ]\n",
      " [ 3.75]\n",
      " [33.5 ]]\n"
     ]
    }
   ],
   "source": [
    "dataset=np.array([2,4,6,3,31,12,15,16,38,35,14,21,23,25,30])\n",
    "from sklearn.cluster import KMeans\n",
    "km=KMeans(n_clusters=3)\n",
    "km.fit(dataset.reshape(-1,1))\n",
    "{print(f'c{i+1}:{dataset[np.where(km.labels_==i)]}') for i in range(km.n_clusters)}\n",
    "print(f'Cluster centers are: \\n{km.cluster_centers_}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds= pd.read_csv('dataset.csv')\n",
    "x=ds.iloc[:,[0,1]]\n",
    "y=ds.iloc[:,2]\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lg=LogisticRegression(solver='lbfgs').fit(x,y)\n",
    "lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1073.1098430813124"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X=np.array([340,1080,640,880,990,510]).reshape(-1, 1)\n",
    "y= np.array([500,1700,1100,800,1400,500]).reshape(-1, 1)\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lg=LinearRegression().fit(X,y)\n",
    "price=lg.predict([[790]])\n",
    "price.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv('knn.csv')\n",
    "ds=ds.drop([0,15])\n",
    "x=ds.iloc[:,:4]\n",
    "y=ds.iloc[:,4]\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "knn=KNeighborsClassifier(n_neighbors=2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "knn.fit(X_train,y_train)\n",
    "pred=knn.predict(X_test)\n",
    "knn.score(X_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can Buy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds=pd.read_csv('COMP_SALE.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for i in ds.columns:\n",
    "    ds[i]=le.fit_transform(ds[i])\n",
    "x=ds.iloc[:,:4]\n",
    "y=ds.iloc[:,4]\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt=DecisionTreeClassifier()\n",
    "dt.fit(x,y)\n",
    "y_pred = dt.predict([[1,0,1,1]])\n",
    "print('Can Buy') if y_pred else print(\"Can't Buy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can Buy\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds = pd.read_csv('Bayes_Classification_Dataset.csv')\n",
    "ds=ds.drop(ds.columns[0],axis=1)\n",
    "ds=ds.drop(14)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for i in ds.columns:\n",
    "    ds[i]=le.fit_transform(ds[i])\n",
    "x=ds.iloc[:,:4]\n",
    "y=ds.iloc[:,4]\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb= GaussianNB(var_smoothing=1e-06)\n",
    "nb.fit(x,y)\n",
    "ypred=nb.predict([[1,2,1,1]])\n",
    "print('Can Buy') if ypred else print('Can\\'t Buy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hebbs rule problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weight:  [ 1.  1. -1.]\n",
      "Update weight:  [ 2.  0. -2.]\n",
      "Update weight:  [ 1.  1. -3.]\n",
      "Update weight:  [ 2.  2. -2.]\n",
      "[-1 -1] is in class -1\n",
      "[-1  1] is in class -1\n",
      "[ 1 -1] is in class -1\n",
      "[1 1] is in class +1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([[-1,-1,1,1],[-1,1,-1,1],[1]*4])\n",
    "y=np.array([-1,-1,-1,1]).reshape(-1,1)\n",
    "x=x.transpose()\n",
    "#initialise weights to zero\n",
    "w=np.zeros(len(x[0]))\n",
    "xy=np.multiply(x,y)\n",
    "for i in range(len(x)):\n",
    "    w+=xy[i]\n",
    "    print('Update weight: ',w)\n",
    "wn=w[:-1]\n",
    "xn=np.delete(x,-1,axis=1)\n",
    "for i in range(len(x)):\n",
    "    yin=w[-1]+sum(np.multiply(xn[i],wn))\n",
    "    if yin>0:\n",
    "        print(f'{xn[i]} is in class +1')\n",
    "    else:\n",
    "        print(f'{xn[i]} is in class -1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hebbs rule problem 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update weight:  [ 1.  1.  1. -1.  1. -1. -1.  1. -1.  1.]\n",
      "Update weight:  [ 0.  0.  0. -2.  2.  0. -2.  0. -2.  0.]\n",
      "[ 1  1  1 -1  1 -1 -1  1 -1] is in class T\n",
      "[ 1  1  1  1 -1 -1  1  1  1] is in class C\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([[1,1,1,-1,1,-1,-1,1,-1,1],[1,1,1,1,-1,-1,1,1,1,1]])\n",
    "y=np.array([[1],[-1]])\n",
    "#initialise weights to zero\n",
    "w=np.zeros(len(x[0]))\n",
    "xy=np.multiply(x,y)\n",
    "for i in range(len(x)):\n",
    "    w+=xy[i]\n",
    "    print('Update weight: ',w)\n",
    "wn=w[:-1]\n",
    "xn=np.delete(x,-1,axis=1)\n",
    "for i in range(len(x)):\n",
    "    yin=w[-1]+sum(np.multiply(xn[i],wn))\n",
    "    if yin>0:\n",
    "        print(f'{xn[i]} is in class T')\n",
    "    else:\n",
    "        print(f'{xn[i]} is in class C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADALINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  32\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "xt=np.array([[1,1,-1,-1],[1,-1,1,-1],[1]*4]).transpose()\n",
    "t=np.array([-1,1,-1,-1])\n",
    "#initialise weights to nonzero values\n",
    "w=np.array([0.2]*3)\n",
    "#initiallise alpha with nonzero value\n",
    "a=0.2\n",
    "e=[0]\n",
    "for k in range(100):\n",
    "    te=[]\n",
    "    for i in range(len(xt)):\n",
    "        #calculate yin\n",
    "        y=sum(np.multiply(xt[i],w))\n",
    "        te.append(t[i]-y)\n",
    "        #check if error is zero or not\n",
    "        if te[i]!=0:\n",
    "            #update weights\n",
    "            w+=a*te[i]*xt[i]\n",
    "    e.append(sum(np.power(te,2)))\n",
    "    if e[k]-e[k-1]==0:\n",
    "        print('Epoch: ',k)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds=pd.read_csv('COMP_SALE.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for i in ds.columns:\n",
    "    ds[i]=le.fit_transform(ds[i])\n",
    "x=ds.iloc[:,:4]\n",
    "y=ds.iloc[:,4]\n",
    "from sklearn.svm import SVC\n",
    "clf = SVC(gamma='auto')\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.2, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "pred=clf.predict(X_test)\n",
    "clf.score(X_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KMEANS without sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1\n",
      "Cluster1:[2, 5, 4, 7, 6, 9, 3]\n",
      "Cluster2:[1, 1]\n",
      "Iteration: 2\n",
      "Cluster1:[5, 4, 7, 6, 9]\n",
      "Cluster2:[2, 1, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x=np.array([2,1,5,1,4,7,6,9,3])\n",
    "c1=x[0]\n",
    "c2=x[1]\n",
    "for k in range(100):\n",
    "    cls1,cls2=[],[]\n",
    "    dc1=abs(np.subtract(c1,x))\n",
    "    dc2=abs(np.subtract(c2,x))\n",
    "    for i in range(len(x)):\n",
    "        if dc1[i]<dc2[i]:\n",
    "            cls1.append(x[i])\n",
    "        else:\n",
    "            cls2.append(x[i])\n",
    "    c3=np.mean(cls1)\n",
    "    c4=np.mean(cls2)\n",
    "    if c1==c3 and c2==c4:\n",
    "        break\n",
    "    else:\n",
    "        print('Iteration:',k+1)\n",
    "        print(f'Cluster1:{cls1}\\nCluster2:{cls2}')\n",
    "        c1,c2=c3,c4\n",
    "        c3,c4=0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
